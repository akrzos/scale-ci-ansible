---
openshift_openstack_clusterid: "{{clusterid}}"
openshift_openstack_public_dns_domain: "{{dns_domain}}"
openshift_openstack_dns_nameservers: ["{{dns_fip.stdout}}"]

# # Used Hostnames
# # - set custom hostnames for roles by uncommenting corresponding lines
#openshift_openstack_master_hostname: "master"
#openshift_openstack_infra_hostname: "infra-node"
#openshift_openstack_cns_hostname: "cns"
#openshift_openstack_node_hostname: "app-node"
#openshift_openstack_lb_hostname: "lb"
#openshift_openstack_etcd_hostname: "etcd"

openshift_openstack_keypair_name: "ci_keypair"
# AKRZOS Commented out value below
openshift_openstack_external_network_name: "public"
{% raw %}
#openshift_openstack_private_network_name:  "openshift-ansible-{{ openshift_openstack_stack_name }}-net"
{% endraw %}
# # A dedicated Neutron network name for containers data network
# # Configures the data network to be separated from openshift_openstack_private_network_name
# # NOTE: this is only supported with Flannel SDN yet
{% raw %}
#openstack_private_data_network_name: "openshift-ansible-{{ openshift_openstack_stack_name }}-data-net"
{% endraw %}
## Kuryr networking
# TODO: Allow the user to specify pre-existing subnets for pod and services
#openshift_openstack_kuryr_service_subnet_cidr: "172.30.0.0/16"

{% if openshift_enable_kuryr|bool %}
## You should set the following if you want to use Kuryr/Neutron as your SDN
openshift_use_kuryr: true
openshift_use_openshift_sdn: false

# NOTE: you must uncomment these for Kuryr to work properly as well:
openshift_master_open_ports:
- service: dns tcp
  port: 53/tcp
- service: dns udp
  port: 53/udp
openshift_node_open_ports:
- service: dns tcp
  port: 53/tcp
- service: dns udp
  port: 53/udp

use_trunk_ports: True
os_sdn_network_plugin_name: cni
openshift_node_proxy_mode: userspace

# # Kuryr needs to know the network or the subnet you will be taking Floating
# IPs for the loadbalancer services from.
kuryr_openstack_public_net_id: {{openshift_kuryr_public_net_id.stdout}}
# If you have different subnet at the Floating IP network you can also specify
# it but need to ensure default policy allows your tennat to retrieve that
# information
# kuryr_openstack_public_subnet_id: uuid_of_my_fip_subnet

# # Kuryr can use a different subnet per namespace
# openshift_kuryr_subnet_driver: namespace
# openshift_kuryr_sg_driver: namespace

# If you VM images will name the ethernet device different than 'eth0',
# override this
#kuryr_cni_link_interface: eth0

## Ports pooling is enabled by default (with nested driver).
## To disable, uncomment the next:
#kuryr_openstack_pool_driver: noop
#
## You can also alter the port pooling defaults here
#kuryr_openstack_pool_max: 0
#kuryr_openstack_pool_min: 1
#kuryr_openstack_pool_batch: 5
#kuryr_openstack_pool_update_frequency: 20
#
## You can pre-populate the pools with subports by uncommenting the next line
## and specifying the amount of subports you want to pre-create per
## origin-node, e.g.: openshift_kuryr_precreate_subports: 5
#openshift_kuryr_precreate_subports: false
#
## You can also change the default device owner for the precreated subports
#openshift_kuryr_device_owner: compute:kuryr
#
# You can also disable the kuryr controller and cni healthcheck probes by
# uncommenting the next
enable_kuryr_controller_probes: false
enable_kuryr_cni_probes: false

openshift_openstack_router_name: ci_router
openshift_openstack_router_id: "{{openshift_kuryr_router_id.stdout}}"
openshift_openstack_node_subnet_name: ci_subnet
openshift_openstack_node_network_id: "{{openshift_kuryr_node_net_id.stdout}}"
openshift_openstack_node_subnet_id: "{{openshift_kuryr_node_subnet_id.stdout}}"

openshift_openstack_master_floating_ip: true
openshift_openstack_infra_floating_ip: true
openshift_openstack_compute_floating_ip: true
openshift_openstack_load_balancer_floating_ip: true
{% else %}
## You should set the following if you want to use Kuryr/Neutron as your SDN
#openshift_use_kuryr: True
#openshift_use_openshift_sdn: False

# NOTE: you must uncomment these for Kuryr to work properly as well:
# openshift_master_open_ports:
# - service: dns tcp
#   port: 53/tcp
# - service: dns udp
#   port: 53/udp
# openshift_node_open_ports:
# - service: dns tcp
#   port: 53/tcp
# - service: dns udp
#   port: 53/udp

#use_trunk_ports: True
#os_sdn_network_plugin_name: cni
#openshift_node_proxy_mode: userspace

# # Kuryr needs to know the network or the subnet you will be taking Floating
# IPs for the loadbalancer services from.
# kuryr_openstack_public_net_id: uuid_of_my_fip_net
# If you have different subnet at the Floating IP network you can also specify
# it but need to ensure default policy allows your tennat to retrieve that
# information
# kuryr_openstack_public_subnet_id: uuid_of_my_fip_subnet

# # Kuryr can use a different subnet per namespace
# openshift_kuryr_subnet_driver: namespace
# openshift_kuryr_sg_driver: namespace

# If you VM images will name the ethernet device different than 'eth0',
# override this
#kuryr_cni_link_interface: eth0

## Ports pooling is enabled by default (with nested driver).
## To disable, uncomment the next:
#kuryr_openstack_pool_driver: noop
#
## You can also alter the port pooling defaults here
#kuryr_openstack_pool_max: 0
#kuryr_openstack_pool_min: 1
#kuryr_openstack_pool_batch: 5
#kuryr_openstack_pool_update_frequency: 20
#
## You can pre-populate the pools with subports by uncommenting the next line
## and specifying the amount of subports you want to pre-create per
## origin-node, e.g.: openshift_kuryr_precreate_subports: 5
#openshift_kuryr_precreate_subports: false
#
## You can also change the default device owner for the precreated subports
#openshift_kuryr_device_owner: compute:kuryr
#
# You can also disable the kuryr controller and cni healthcheck probes by
# uncommenting the next
# enable_kuryr_controller_probes: False
# enable_kuryr_cni_probes: False
{% endif %}

{% if openshift_enable_kuryr|bool %}
## If you want to use a provider network, set its name here.
## NOTE: the `openshift_openstack_external_network_name` and
## `openshift_openstack_private_network_name` options will be ignored when using a
## provider network.
# openshift_openstack_provider_network_name: "ci_network"
{% else %}
## If you want to use a provider network, set its name here.
## NOTE: the `openshift_openstack_external_network_name` and
## `openshift_openstack_private_network_name` options will be ignored when using a
## provider network.
openshift_openstack_provider_network_name: "ci_network"
{% endif %}

# # Used Images
# # - set specific images for roles by uncommenting corresponding lines
# # - note: do not remove openshift_openstack_default_image_name definition
#openshift_openstack_master_image_name: "centos7"
#openshift_openstack_infra_image_name: "centos7"
#openshift_openstack_cns_image_name: "centos7"
#openshift_openstack_node_image_name: "centos7"
#openshift_openstack_lb_image_name: "centos7"
#openshift_openstack_etcd_image_name: "centos7"
openshift_openstack_default_image_name: "{{openshift_default_image_name}}"

openshift_openstack_num_masters: 3
openshift_openstack_num_infra: 3
openshift_openstack_num_cns: 3
openshift_openstack_num_nodes: "{{openshift_node_target}}"

# # Public IP Allocation
# # - manage which node roles are allocated public IP addresses
# # - by default, all roles are given Public IP addresses
#openshift_openstack_master_floating_ip: true
#openshift_openstack_infra_floating_ip: true
#openshift_openstack_etcd_floating_ip: true
#openshift_openstack_load_balancer_floating_ip: true
#openshift_openstack_compute_floating_ip: true

# # Used Flavors
# # - set specific flavors for roles by uncommenting corresponding lines
# # - note: do note remove openshift_openstack_default_flavor definition
openshift_openstack_master_flavor: "{{openshift_master_flavor}}"
openshift_openstack_infra_flavor: "{{openshift_infra_flavor}}"
openshift_openstack_cns_flavor: "{{openshift_cns_flavor}}"
openshift_openstack_node_flavor: "{{openshift_node_flavor}}"
openshift_openstack_lb_flavor: "{{openshift_lb_flavor}}"
#openshift_openstack_etcd_flavor: "m1.medium"
openshift_openstack_default_flavor: "{{openshift_default_flavor}}"

# # Numerical index of nodes to remove
# openshift_openstack_nodes_to_remove: []


## Select a load balancer solution you desire. Only one of these can be
## `true` at a time. If they're both `false`, no load balancer will be deployed.
{% if openshift_enable_kuryr|bool %}
openshift_openstack_use_lbaas_load_balancer: true
openshift_openstack_use_vm_load_balancer: false
{% else %}
openshift_openstack_use_lbaas_load_balancer: false
openshift_openstack_use_vm_load_balancer: true
{% endif %}

# # Docker volume size
# # - set specific volume size for roles by uncommenting corresponding lines
# # - note: do not remove docker_default_volume_size definition
#openshift_openstack_master_volume_size: "15"
#openshift_openstack_infra_volume_size: "15"
#openshift_openstack_cns_volume_size: "15"
#openshift_openstack_node_volume_size: "15"
#openshift_openstack_etcd_volume_size: "2"
#openshift_openstack_lb_volume_size: "5"
openshift_openstack_docker_volume_size: "15"

## Specify server group policies for master and infra nodes. Nova must be configured to
## enable these policies. 'anti-affinity' will ensure that each VM is launched on a
## different physical host.
#openshift_openstack_master_server_group_policies: [anti-affinity]
#openshift_openstack_infra_server_group_policies: [anti-affinity]


# The Classless Inter-Domain Routing (CIDR) for the OpenStack VM subnet.
openshift_openstack_subnet_cidr: "192.168.0.0/16"
# The starting IP address for the OpenStack subnet allocation pool.
openshift_openstack_pool_start: "192.168.0.3"
# The ending IP address for the OpenStack subnet allocation pool.
openshift_openstack_pool_end: "192.168.255.254"

## Red Hat subscription using user/password
#rhsub_user: '<username>'
#rhsub_pass: '<password>'
# Or if using activation key:
#rhsub_ak: '<ak>'
#rhsub_orgid: '<orgid>'
#rhsub_pool: '<pool name>'


# # Roll-your-own DNS
#openshift_openstack_external_nsupdate_keys:
#  public:
#    key_secret: 'SKqKNdpfk7llKxZ57bbxUnUDobaaJp9t8CjXLJPl+fRI5mPcSBuxTAyvJPa6Y9R7vUg9DwCy/6WTpgLNqnV4Hg=='
#    key_algorithm: 'hmac-md5'
#    server: '192.168.1.1'
#  private:
#    key_secret: 'kVE2bVTgZjrdJipxPhID8BEZmbHD8cExlVPR+zbFpW6la8kL5wpXiwOh8q5AAosXQI5t95UXwq3Inx8QT58duw=='
#    key_algorithm: 'hmac-md5'
#    server: '192.168.1.2'
{{ nsupdate_contents['stdout'] }}

# NOTE(shadower): Do not change this value. The Ansible user is currently
# hardcoded to `openshift`.
ansible_user: openshift

# Resolve heat stack outputs. Disabling outputs helps stack scalability. (default: True)
openshift_openstack_resolve_heat_outputs: false

# # Use a single security group for a cluster (default: false)
#openshift_openstack_flat_secgrp: false

# If you want to use the VM storage instead of Cinder volumes, set this to `true`.
# NOTE: this is for testing only! Your data will be gone once the VM disappears!
openshift_openstack_ephemeral_volumes: true

## cloud config
openshift_openstack_disable_root: false
openshift_openstack_user: openshift

# Remaining Options:
openshift_openstack_public_hostname_suffix: '-public'
openshift_openstack_heat_template_version: '2016-10-14'
openshift_openstack_cns_secgroup_rules: []
openshift_openstack_infra_secgroup_rules: []
openshift_openstack_lb_base_secgroup_rules: []
openshift_openstack_lb_console_secgroup_rules: []
openshift_openstack_master_secgroup_rules: []
openshift_openstack_node_secgroup_rules: []
openshift_openstack_etcd_secgroup_rules: []
openshift_openstack_etcd_flat_secgroup_rules: []
openshift_openstack_common_secgroup_rules:
  - direction: ingress
    protocol: icmp
  - direction: ingress
    protocol: tcp
    port_range_min: 22
    port_range_max: 65535
  - direction: ingress
    protocol: udp
    port_range_min: 22
    port_range_max: 65535
